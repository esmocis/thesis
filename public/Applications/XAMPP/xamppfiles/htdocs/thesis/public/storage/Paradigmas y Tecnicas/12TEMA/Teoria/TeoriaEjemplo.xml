<titulo>Knuth Morris and Pratt.</titulo>
<subtitulo>Motivación</subtitulo>
<texto>Consideremos el siguiente par de cadenas de caracteres `T = a_1a_2a_3...a_n` y `P = b_1b_2b_3...b_m`, estámos interesados en buscar el numero de ocurrencias de `P` en `T`.</texto>
<subtitulo>Descripción del Algoritmo: </subtitulo>
<texto>Para resolver este problema, podríamos realizar una rutina simple empleando una fuerza bruta que en esencia se encargaría de probar para cada posición en `T`, si es que `P` está contenido apartir de dicha posición, siguiendo esa idea, lograríamos contar el numero de apariciones de `P` en `T`, sin embargo la complejidad no sería del todo óptima, en especial para cadenas largas. A continuación explicaremos el algoritmo descrito por Donald Knuth, James Morris y V. Pratt, el cuál logra resolver el problema, usando una mejor estrategia.</texto>
<texto> Antes de introducir algunos elementos que juegan un papel importante en el algoritmo, analicemos la solucion con fuerza bruta de modo que veamos el porqué el algoritmo es poco eficiente, en cuestión.</texto>
<codigo>
void naiveStringMatching(){
	int N = T.size();
	int M = P.size();
	for(int i = 0; i < N; i++){
	  int found = 1;
	  for(int j = 0; j < M && f; j++)
	    if(i + j >= N || T[i + j] != P[j])
	      found &= 0;
	  if(found)
	    cout << "Found at " << i << endl;
	}
}
</codigo>
<texto>
 El código descrito arriba, pese a que puede correr en promedio en `\Theta(|T|)` si es aplicado a texto natural, como algun parrafo de un libro, en el peor de los casos con una entrada como `T = {XXXXXXXXXB}` y `P = {XXXB}`, corre en `O(n × m)`, donde `n = |T|, m = |P|`. Lo interesante es ver que para esa entrada en particular, el algoritmo se mantiene tomando cada caractér de `T` como posible inicio de la cadena `P` para posteriormente realizar la búsqueda apartir de ahí, como se puede observar, el algoritmo dirá que no se encontro el último caractér de `P` durante múltiples iteraciones, poco después de haber fallado en encontrar al último elemento de `P`, intentará tomar como inicio al siguiente caracter de `T`, precisamente eso es lo que lo hace tan ineficiente. En contraste, la idea del algoritmo KMP, es precomputar una función `\varphi : \mathbb{N} to \mathbb{N}` a través de una serie de comparaciones de caracteres sobre `P`, de modo que cuando falle una aparición de `P` en `T` o cuando hayamos llegado a una ocurrencia total, se emplee la funcion `\varphi`, para redireccionar al siguiente posible inicio de `P` sobre `T`.
 </texto>
<texto>
Hasta el momento, sabemos que `\varphi` nos indicara la posición desde la cual tendrá sentido intentar encontrar a `P` una vez que ocurra una falla en la aparicion de un caracter, o una aparicion total de `P` sobre `T`. La complejidad del algoritmo en cuestion, recae en la construcción de `\varphi`, para hablar de ello, primero introduciremos un par de definiciones.
</texto>
<texto>`\equiv` Sea una cadena `A = a_1a_2a_3...a_n`, definimos un prefijo propio de A, como una cadena `P_A = a_1a_2...a_m | m < n`.</texto>
<texto>
`\equiv` De manera análoga, el sufijo propio de una cadena `A = a_1a_2a_3...a_n` es una cadena `S_A = a_ka_(k+1)...a_n | 1 < k <= n`.</texto>
<texto>
`\equiv` Por otra parte, definimos al borde de una cadena `A = a_1a_2a_3...a_n` como toda cadena `B`, que es tanto `P_A` como `S_A`.</texto>
<texto>
Antes de hablar del modo en que se construye `\varphi`, asumamos que contamos con `\varphi`, entendiendo a `\varphi(i)` como la longitud máxima del borde considerado hasta el caractér `i` de la cadena sobre la cuál se esté trabajando, para este caso `P`. Ilustrémoslo con el siguiente ejemplo.
</texto>
<texto>
Asumiendo lo anterior, analicemos cómo es que buscariamos a P sobre T a través de una rutina en donde se emplee a `\varphi`. Para comenzar, es importante hacer esta primer observación. 
</texto>
<texto>
<u>`\diamond` Por definición, si `\varphi_k` es borde de la cadena `A`, también es sufijo de `A`. Observemos que todos los posibles sufijo de `\varphi_k` también serán sufijos de `A`.</u>
</texto>
<codigo>
void KMPSearch(string T, string P){
	int M = strlen(P);
	int N = strlen(T);
	int phi[M];
	computePhi(P, M, phi); 
	int i = 0; 
	int j  = 0;
	while (i < N){
	    if (pat[j] == txt[i])
	        j++, i++;
	    if (j == M)  // Match en (i - j).
	        j = phi[j-1];
	    else if (i < N && P[j] != T[i]){
	        if (j != 0)
	            j = phi[j-1];
	        else
	            i = i+1;
	    }
	}
} 
</codigo>
<texto>
La idea intuitiva de la búsqueda una vez asumiendo que contamos con la función `\varphi`, en esencia es la siguiente:
</texto>
<texto>
`\quad 1.-` Empezamos comparando los caracteres de `P`, `p_j` desde `j = 0` con la ventana actual de `T`.
</texto>
<texto>
 `\quad 2.-` Mientras los caracteres de `T` vayan emparejandose con los de `P`, es decir `p_j = t_i`, vamos moviendo ambos indices. 
</texto>
<texto>
`\quad 3.-` Cuando ocurra algún fallo de caracter, es decir que `p_j != t_i`:
</texto>
<texto>
`\quad \quad \quad \quad \quad \quad  4.-` Sabemos que hasta este punto `p_0p_1...p_(j-1) = t_(i-j+1)...t_(i-1)`.
</texto>
